---
layout: talk
type: "Talk"
date: 2025-05-14
name: "Qianhui Men"
teaser: "Multimodal AI for Healthcare Decision-Making: Integrating Visual and Motion Guidance in Fetal Ultrasound Navigation"
link: "/talks/qianhui_men"
---

### Speaker 
Qianhui Men is a Lecturer working in the field of computer vision for digital health in the School of Engineering Mathematics and Technology, University of Bristol. Before joining Bristol, she was a postdoctoral researcher in Prof. Alison Noble’s group in University of Oxford, working on the projects PULSE and Turing AI WLR Fellowship. She received her Ph.D. degree in the Department of Computer Science from City University of Hong Kong, supervised by Prof. Howard Leung. She was also a visiting student in Prof. Hubert P. H. Shum’s and Prof. Edmond S. L. Ho’s groups. She obtained her M.S. degree from National University of Singapore, and B.S. degree from Dalian University of Technology. She received MICCAI Yong Scientist Award in 2022.

Speaker Links: [Google Scholar](https://scholar.google.ca/citations?user=t1hraiAAAAAJ)

### Abstract 
The integration of multimodal AI into healthcare is transforming human decision-making by enhancing real-time guidance in complex medical procedures. Ultrasound scanning, a widely used yet highly operator-dependent imaging technique, requires refined hand-eye coordination to interpret images and manipulate the probe simultaneously. This talk explores how multimodal AI-driven guidance systems can improve sonographic decision-making by integrating visual and motion-based intelligence for more accurate and efficient fetal biometry Standard Plane acquisition—a critical task in obstetric examinations. I will first introduce our sensor-based multimodal ultrasound guidance system, which employs deep learning to integrate ultrasound imaging, gaze tracking, and probe motion, offering adaptive, real-time guidance to reduce skill dependency and enhance scan consistency. Building on this, I will present a sensor-free AI framework using a 3D fetal atlas for pose estimation and navigation, improving interpretability, accessibility, and eliminating reliance on external motion sensors. This seminar will discuss the broader impact of AI-assisted sonographic navigation, its potential to train non-specialists, and its role in making ultrasound scanning more precise, accessible, and autonomous.