---
layout: talk
type: "Talk"
date: 2025-07-09
name: "Brittany Cates"
teaser: "Trust Issues: Modeling Lies and Deception in Artificial Agents"
link: "/talks/brittany_cates"
---

### Speaker 
Brittany Cates is a Ph.D. student of computer science in the [Human-Aware Planning and Interaction (HAPI) lab](https://hapi-lab.org/) at Colorado State University. Her work centers on adversarial learning and the modeling of intentional deception in AI systems. With academic roots in psychology and data science, her research bridges human cognitive modeling and machine decision-making. Her interests include human-aware planning, theory of mind, behavioral economics, nudging, and game-theory. A central focus of her work is the use of computational frameworks that mimic or manipulate mental models to achieve adversarial and cooperative goals.

### Abstract 
As generative AI continues to reshape communication and information ecosystems, concerns around misinformation have surged. But what if the AI itself could lie—on purpose? In this talk, we’ll explore intentional deception by artificial agents. What defines a lie for an AI system? What cognitive scaffolding—like beliefs, intentions, or theory of mind—would be required for a machine to deceive? Drawing on work recently presented at the Rebellious and Deceptive AI (RaD-AI) workshop at AAMAS, we’ll examine how mental modeling can be leveraged to automatically generate lies for the purpose of simulating insider threats. Explicitly modeling deceptive behaviors, such as lying, allows for the exploration of a greater range of issues concerning trust and security in autonomous systems.