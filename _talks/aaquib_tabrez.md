---
layout: talk
type: "Talk"
date: 2023-11-09
name: "Aaquib Tabrez"
teaser: "Building Trust and Transparency in Human-Robot Teams through Explainable Multimodal Communication"
link: "/talks/aaquib_tabrez"
---

### Speaker 
Aaquib is a Ph.D. student in the Collaborative AI and Robotics Lab at the University of Colorado Boulder in the Department of Computer Science, where he is advised by Prof. Brad Hayes. Aaquib works at the intersection of explainability and human-robot interaction, aiming to leverage and enhance multimodal human-machine communication for value alignment and fostering appropriate trust within human-robot teams. Specifically, he develops and operationalizes novel explainable AI techniques for succinctly conveying robot plan explanations using natural language and augmented reality modalities to enable shared understanding within human-robot teams, enhancing safety, transparency, and trust across diverse tasks.  He's an RSS and HRI Pioneer, and his work has earned best paper nomination awards from the HRI and AAMAS communities. 

Speaker Links: [Website](https://aaquibtabrez.github.io/) - [Google Scholar](https://scholar.google.com/citations?user=Kx6BthoAAAAJ&hl=en)

### Abstract 
Effective communication is an essential aspect of human-robot collaboration, for improving task efficiency, fluency, and safety. Good communication between teammates provides shared situational awareness, enabling adaptation and improvisation during uncertain situations, and helping identify and remedy potential misunderstandings arising from incongruous mental models. In this talk, I will discuss how to leverage visual (augmented reality) and semantic (spoken language) modalities to enable explainable decision support in human-robot teams, enhancing trust and transparency, and empowering human teammates to act more independently under uncertainty. I will introduce our recent framework on autonomous justification, grounded in the value of information theory, which allows robots to strategically time justifications during periods of misaligned expectations to improve performance, assist users in making informed decisions, and promote greater interpretability. Finally, I will present an evaluation of different types of multimodal counterfactual justifications and provide insights into human behavior and compliance in safety-critical, partially observable situations while grounding these findings in real-world decision-support systems for human-robot teaming.

### Papers
* (HRI 2019) Explanation-based Reward Coaching to Improve Human Performance via Reinforcement Learning, [Link](https://ieeexplore.ieee.org/document/8673104)
* (AAMAS 2022) Descriptive and Prescriptive Visual Guidance to Improve Shared Situational Awareness in Human-Robot Teaming, [Link](https://dl.acm.org/doi/abs/10.5555/3535850.3535990)
* (RSS 2023) Autonomous Justification for Enabling Explainable Decision Support in Human-Robot Teaming, [Link](https://www.roboticsproceedings.org/rss19/p002.pdf)
